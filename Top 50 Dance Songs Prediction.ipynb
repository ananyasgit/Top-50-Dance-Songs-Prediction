{"cells":[{"source":"## üí™ Challenge\nYour task is to devise an analytically-backed, dance-themed playlist for the company's summer party. Your choices must be justified with a comprehensive report explaining your methodology and reasoning. Below are some suggestions on how you might want to start curating the playlist:\n* Use descriptive statistics and data visualization techniques to explore the audio features and understand their relationships.\n* Develop and apply a machine learning model that predicts a song's `danceability`. \n* Interpret the model outcomes and utilize your data-driven insights to curate your ultimate dance party playlist of the top 50 songs according to your model.","metadata":{},"cell_type":"markdown","id":"54e0ae0c-ff96-443e-9ff3-718f1ab846e5"},{"source":"## üíæ The Data\nYou have assembled information on more than `125` genres of Spotify music tracks in a file called `spotify.csv`, with each genre containing approximately `1000` tracks. All tracks, from all time, have been taken into account without any time period limitations. However, the data collection was concluded in `October 2022`.\nEach row represents a track that has some audio features associated with it.\n\n| Column     | Description              |\n|------------|--------------------------|\n| `track_id` | The Spotify ID number of the track. |\n| `artists` | Names of the artists who performed the track, separated by a `;` if there's more than one.|\n| `album_name` | The name of the album that includes the track.|\n| `track_name` | The name of the track.|\n| `popularity` | Numerical value ranges from `0` to `100`, with `100` being the highest popularity. This is calculated based on the number of times the track has been played recently, with more recent plays contributing more to the score. Duplicate tracks are scored independently.|\n| `duration_ms` | The length of the track, measured in milliseconds.|\n| `explicit` | Indicates whether the track contains explicit lyrics. `true` means it does, `false` means it does not or it's unknown.|\n| `danceability` | A score ranges between `0.0` and `1.0` that represents the track's suitability for dancing. This is calculated by algorithm and is determined by factors like tempo, rhythm stability, beat strength, and regularity.|\n| `energy` | A score ranges between `0.0` and `1.0` indicating the track's intensity and activity level. Energetic tracks tend to be fast, loud, and noisy.|\n| `key` | The key the track is in. Integers map to pitches using standard Pitch class notation. E.g.`0 = C`, `1 = C‚ôØ/D‚ô≠`, `2 = D`, and so on. If no key was detected, the value is `-1`.| \n| `loudness` | The overall loudness, measured in decibels (dB).|\n| `mode` |  The modality of a track, represented as `1` for major and `0` for minor.| \n| `speechiness` | Measures the amount of spoken words in a track. A value close to `1.0` denotes speech-based content, while `0.33` to `0.66` indicates a mix of speech and music like rap. Values below `0.33` are usually music and non-speech tracks.| \n| `acousticness` | A confidence measure ranges from `0.0` to `1.0`, with `1.0` representing the highest confidence that the track is acoustic.|\n| `instrumentalness` | Instrumentalness estimates the likelihood of a track being instrumental. Non-lyrical sounds such as \"ooh\" and \"aah\" are considered instrumental, whereas rap or spoken word tracks are classified as \"vocal\". A value closer to `1.0` indicates a higher probability that the track lacks vocal content.|\n| `liveness` | A measure of the probability that the track was performed live. Scores above `0.8` indicate a high likelihood of the track being live.|\n| `valence` | A score from `0.0` to `1.0` representing the track's positiveness. High scores suggest a more positive or happier track.|\n| `tempo` | The track's estimated tempo, measured in beats per minute (BPM).|\n| `time_signature` | An estimate of the track's time signature (meter), which is a notational convention to specify how many beats are in each bar (or measure). The time signature ranges from `3` to `7` indicating time signatures of `3/4`, to `7/4`.|\n| `track_genre` |  The genre of the track.|\n\n[Source](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset) (data has been modified)","metadata":{"tags":[]},"id":"10dcc269-3659-4851-99cd-f1ffb7f818aa","cell_type":"markdown"},{"source":"# üìú Executive Summary:\n\nThis report provides a comprehensive analysis of a music dataset, focusing on danceability as a key attribute, and explores various aspects of data preprocessing, genre analysis, audio features, and machine learning modeling. The objective of this analysis is to gain insights into the factors that influence danceability and create a playlist of songs optimized for danceability.\n\n**Data Exploration:** Initial data inspection using .info() and .describe() functions to understand dataset structure and statistics. Plotting visualizations to gain insights.\n\n**Data Pre-processing:** Duplicate entries are removed for data accuracy. Missing values are imputed.\n\n**Genre Analysis:** An exploration of music genres' distribution in the dataset, providing insights for subsequent genre-based investigations.Analysis of how different genres correlate with danceability scores, helping identify high-danceability genres.\n\n**Feature Correlation:** Visualization of feature correlations with danceability through a heatmap and histograms, offering insights into feature importance.\n\n**Clustering**:K-Means clustering is used to cluster the genres, the elbow method is used to find the optimal number of clusters based on song danceability and valence.\n\n**ML Modeling**: After the validation of the chosen ML models,The KNN Regressor Machine learning model is used to predict danceability scores based on selected features. Feature selection, data splitting, and performance evaluation are done to ensure the most optimal results.\n\n**Playlist Creation:** A curated dance playlist is generated based on the analysis and modeling results, catering to dance enthusiasts.\n\n**Playlist Refining** : Refining the playlist with a weight based algorithm","metadata":{},"cell_type":"markdown","id":"7751267a-f150-4cd8-9b67-05aefa558dc5"},{"source":"## üë©‚Äçüíª Reading Data\n\nIn this step, we read the necessary data for our analysis. The dataset was provided by the competition and originally sourced from Kaggle.\nFor this task, let's import the pandas library and use it to unveil our dataset.","metadata":{},"cell_type":"markdown","id":"9c909e71-f313-4b17-9076-5c6e797074ba"},{"source":"import pandas as pd\nspotify = pd.read_csv('data/spotify.csv')\nspotify","id":"40251159-3eea-47f8-bfb4-09e38d5ced65","cell_type":"code","outputs":[],"metadata":{"executionCancelledAt":null,"executionTime":416,"lastExecutedAt":1696001910044,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nspotify = pd.read_csv('data/spotify.csv')\nspotify","outputsMetadata":{"0":{"height":331,"type":"dataFrame"}}},"execution_count":88},{"source":"## üîé Exploring the Data\n\nIn this step, we will explore the dataset to gain insights and understand the structure of the data.\n\nLet's start by examining the first few rows of the dataset.\n","metadata":{},"cell_type":"markdown","id":"c8912502-6d6b-4e31-96be-439a0c199f12"},{"source":"spotify.head()","metadata":{"executionCancelledAt":null,"executionTime":60,"lastExecutedAt":1696001910104,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"spotify.head()","outputsMetadata":{"0":{"height":210,"type":"dataFrame"}}},"cell_type":"code","id":"8dbe8847-2443-4f94-ac0a-deb3a9739d5a","execution_count":89,"outputs":[]},{"source":"Looks like we have got a lot of da'ta'cing to do!","metadata":{},"cell_type":"markdown","id":"d28fe230-89a6-4bd7-9458-3972e62d11b3"},{"source":"## Using the `.info()` function\n\nThe `.info()` function is a useful method in pandas that provides a concise summary of a DataFrame. It gives information about the column names, the number of non-null values, and the data types of each column.\nUsing the `.info()` function is a quick way to get an overview of the structure and content of a DataFrame.","metadata":{},"cell_type":"markdown","id":"cf924300-fd6f-4c2a-96c0-3fdaebc6a617"},{"source":"spotify.info()","metadata":{"executionCancelledAt":null,"executionTime":79,"lastExecutedAt":1696001910183,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"spotify.info()","outputsMetadata":{"0":{"height":543,"type":"stream"}}},"cell_type":"code","id":"f573644b-fdab-4538-8db6-dccfab28867f","execution_count":90,"outputs":[]},{"source":"### **Recommendation**","metadata":{},"cell_type":"markdown","id":"af84e005-c939-44b2-8b47-368485203d3e"},{"source":"## What do we know so far? ü§î\n**Dataset Size:** The dataset contains a total of 113,027 entries or rows.\n\n**Columns:** There are 20 columns in this dataset, each representing different attributes of music tracks.\n\n**Data Types:**\n\n- Most columns contain numeric data types, including integers (int64) and floating-point numbers (float64).\n- The explicit column is represented as a boolean (bool) data type, indicating whether a track contains explicit content.\n- Several columns, such as track_id, artists, album_name, track_name, and track_genre, are of object (object) data type, which typically represents strings or categorical data.","metadata":{},"cell_type":"markdown","id":"9e95823c-c7cb-47bb-9603-000e4a6ed19c"},{"source":"## Using the `.describe()` function\n\nThe `.describe()` function is a useful method in pandas that provides descriptive statistics of a DataFrame. It gives information about the count, mean, standard deviation, minimum, maximum, and quartiles of the numerical columns in the DataFrame.\n\nUsing the `.describe()` function is a quick way to get an overview of the distribution and summary statistics of the numerical data in a DataFrame.\n","metadata":{},"cell_type":"markdown","id":"6a32c717-841d-4514-be75-033cd6dffbac"},{"source":"spotify.describe()","metadata":{"executionCancelledAt":null,"executionTime":88,"lastExecutedAt":1696001910272,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"spotify.describe()","outputsMetadata":{"0":{"height":283,"type":"dataFrame"}}},"cell_type":"code","id":"acdb1e57-0c45-43a5-88e1-29a78c1f88eb","execution_count":91,"outputs":[]},{"source":"### Recommendation","metadata":{},"cell_type":"markdown","id":"29353b34-5a62-4d58-b764-0f9e5b07928c"},{"source":"By carefully observing the above result, we get a clearer picture of how data is distributed over each numerical column. Few observations that can be inferred are-\n- Popularity, duration, key, loudness, tempo and time_signature have occurences that go beyond the range of 0-1 and would need to be dealt with differently.\n- 25% of values in instrumentalness are less than or equal to 0 which can be imputed.\n- 75% of values in mode are equal to 1, so mode can be dropped from the feature selection process as it conveys little information about each individual track.","metadata":{},"cell_type":"markdown","id":"a8cbcaeb-6dd0-4c94-bd70-d420ec91c334"},{"source":"## Time to put our 'data dancing' shoes ON!\nNow that we have a statistical picture of what is going on in our dataset. Let us start exploring and pre-processing our data for the best results.","metadata":{},"cell_type":"markdown","id":"fa16f14b-cba5-4279-a82e-3250eef31fb9"},{"source":"### Dropping duplicates","metadata":{},"cell_type":"markdown","id":"9a5a957f-3b21-412f-adde-3254d414d193"},{"source":"The dataset has many song tracks which are repeated because of the different albums or genres they belong to. (One-to-many relationship). So let us first find out the actual number of unique tracks in our data.\nThis code below calculates and stores the count of unique track names in a Spotify dataset and then assigns this count to the variable track_count.","metadata":{},"cell_type":"markdown","id":"20bbbdd8-e360-4865-af25-5cf53a0e999a"},{"source":"track_count=len(spotify.track_name.unique())\ntrack_count","metadata":{"executionCancelledAt":null,"executionTime":60,"lastExecutedAt":1696001910332,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"track_count=len(spotify.track_name.unique())\ntrack_count"},"cell_type":"code","id":"a371b4b3-f9d8-455d-a536-5df249b5552c","execution_count":92,"outputs":[]},{"source":"Might as well find the number of duplicated tracks-","metadata":{},"cell_type":"markdown","id":"f142063d-8856-4d01-ad94-7c3d5ca62a42"},{"source":"duplicate_rows = spotify[spotify.duplicated(['track_name'])]\nlen(duplicate_rows)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1696001910388,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"duplicate_rows = spotify[spotify.duplicated(['track_name'])]\nlen(duplicate_rows)"},"cell_type":"code","id":"2b20c20c-1553-4e45-a0f2-270805524a1f","execution_count":93,"outputs":[]},{"source":"That is quite a number of duplicates. Now let us drop them, ensuring that we retain the first occurence of every duplicate track name and make our dataset a little easier to deal with. However, doing this might result in the information loss related to genres as the same song can belong to different genres. Although, doing this is the viable option to keep redundancy in check.","metadata":{},"cell_type":"markdown","id":"2b8c8b1d-9dff-4029-a767-fbf7bacfa9b4"},{"source":"spotify = spotify.drop_duplicates(subset=['track_name'])\nspotify","metadata":{"outputsMetadata":{"0":{"height":331,"type":"dataFrame"}},"executionCancelledAt":null,"executionTime":156,"lastExecutedAt":1696001910545,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"spotify = spotify.drop_duplicates(subset=['track_name'])\nspotify"},"cell_type":"code","id":"f4c03ac9-757b-4f0f-ae8e-fdd20778a2d0","execution_count":94,"outputs":[]},{"source":"### üìä Genre Analysis\n\nThe genre of a song plays a significant role in its overall appeal and popularity. It enables music platforms and recommendation systems to suggest similar songs or artists based on a user's preferences. This facilitates music discovery and allows listeners to explore new genres and expand their musical horizons.\nIn our case, genre analysis would lead us to curate a relevant dance music playlist for our company!","metadata":{},"cell_type":"markdown","id":"3235123c-1ca8-48a3-b746-3a749c3fc142"},{"source":"Initally, the dataset had 125 unique genres. After dropping duplicates we have 113 unique genres as illustrated by the code below:","metadata":{},"cell_type":"markdown","id":"78869769-d38e-4a85-80ff-908c58dbf907"},{"source":"genres = spotify.track_genre.unique()\nlen(genres)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1696001910596,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"genres = spotify.track_genre.unique()\nlen(genres)"},"cell_type":"code","id":"adf29d02-f3dc-4730-a89b-628b2341ebe8","execution_count":95,"outputs":[]},{"source":"The distribution of song tracks across genres can be better perceived using visulization like the one demonstrated below. ","metadata":{},"cell_type":"markdown","id":"c6dcbe56-781a-49ba-9076-2faf6a543229"},{"source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 6))\nsns.countplot(data=spotify, x='track_genre', order=spotify['track_genre'].value_counts().index, palette='viridis')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.title('Distribution of Data by Genre')\nplt.xticks(rotation=90)  # Rotate x-axis labels for readability\nplt.tight_layout()\n# Show the plot\nplt.show()","metadata":{"executionCancelledAt":null,"executionTime":768,"lastExecutedAt":1696001911364,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 6))\nsns.countplot(data=spotify, x='track_genre', order=spotify['track_genre'].value_counts().index, palette='viridis')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.title('Distribution of Data by Genre')\nplt.xticks(rotation=90)  # Rotate x-axis labels for readability\nplt.tight_layout()\n# Show the plot\nplt.show()"},"cell_type":"code","id":"2267e8bf-24c2-44dc-8906-b6c6f3ad1872","execution_count":96,"outputs":[]},{"source":"### Recommendation","metadata":{},"cell_type":"markdown","id":"c4e0ea81-4bec-4332-9e98-0b6e7977d60f"},{"source":"Based on the genre count plot, we can make the following recommendations:\n\n1. Explore more songs in the genres with the highest count to discover popular and trending tracks. Metal based songs have highest frequency, followed by afrobeat and cantopop.\n2. We can consider diversifying the playlist by including songs from genres with lower counts such as indie house and reggaeton.\n3. Analyze the characteristics of songs in different genres to understand the preferences of the target audience.","metadata":{},"cell_type":"markdown","id":"f61fe90e-8137-4d55-b54c-5cd0794c8c07"},{"source":"The above can also be interpretted as below using **.value_counts()** function","metadata":{},"cell_type":"markdown","id":"a4952292-e6c0-4a1d-ba6d-c0d67b60cec9"},{"source":"genre_counts =spotify['track_genre'].value_counts()\ngenre_counts","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1696001911416,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"genre_counts =spotify['track_genre'].value_counts()\ngenre_counts"},"cell_type":"code","id":"4475a621-c925-4889-8763-e76da638e3a9","execution_count":97,"outputs":[]},{"source":"Here is a view of all types of unique genres in our data for better readibility-","metadata":{},"cell_type":"markdown","id":"6f7aea8a-d58d-4c17-82f6-00bbb2323c66"},{"source":"genres","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1696001911465,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"genres","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"a14b552e-cb61-416c-bc09-b0685a509df1","execution_count":98,"outputs":[]},{"source":"### Genre Vs Danceability\nA song's genre can tell a lot about whether a song is danceable or not. Songs belonging to genres like sad,metal,sleep etc. can definitely not qualify as danceable and hence the distrubution of danceability across various genres needs to be kept in mind. ","metadata":{},"cell_type":"markdown","id":"fa03cabc-43fd-4409-bf7b-7cbda00fe9b6"},{"source":"This code below creates three **boxplots** using Seaborn to visualize the distribution of danceability scores for music genres in the dataset, dividing the genres into thirds since one boxplot would lead to overcrowding.","metadata":{},"cell_type":"markdown","id":"b64023f1-3f9b-4e38-91ae-65b39107b114"},{"source":"def create_genre_boxplot(data, title):\n    sns.boxplot(data=data, x='track_genre', y='danceability', width=0.6)\n    plt.xlabel('Genre')\n    plt.ylabel('Danceability')\n    plt.title(title)\n    plt.xticks(rotation=90)\n    plt.show()\n\nthird = len(genres) // 3\ngenres1 = genres[:third]\ngenres2 = genres[third:2*third]\ngenres3 = genres[2*third:]\n\nsubset1 = spotify[spotify['track_genre'].isin(genres1)]\ncreate_genre_boxplot(subset1, 'Boxplot of Danceability for First Third of Genres')\n\nsubset2 = spotify[spotify['track_genre'].isin(genres2)]\ncreate_genre_boxplot(subset2, 'Boxplot of Danceability for Second Third of Genres')\n\nsubset3 = spotify[spotify['track_genre'].isin(genres3)]\ncreate_genre_boxplot(subset3, 'Boxplot of Danceability for Final Third of Genres')","metadata":{"executionCancelledAt":null,"executionTime":2026,"lastExecutedAt":1696001913491,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def create_genre_boxplot(data, title):\n    sns.boxplot(data=data, x='track_genre', y='danceability', width=0.6)\n    plt.xlabel('Genre')\n    plt.ylabel('Danceability')\n    plt.title(title)\n    plt.xticks(rotation=90)\n    plt.show()\n\nthird = len(genres) // 3\ngenres1 = genres[:third]\ngenres2 = genres[third:2*third]\ngenres3 = genres[2*third:]\n\nsubset1 = spotify[spotify['track_genre'].isin(genres1)]\ncreate_genre_boxplot(subset1, 'Boxplot of Danceability for First Third of Genres')\n\nsubset2 = spotify[spotify['track_genre'].isin(genres2)]\ncreate_genre_boxplot(subset2, 'Boxplot of Danceability for Second Third of Genres')\n\nsubset3 = spotify[spotify['track_genre'].isin(genres3)]\ncreate_genre_boxplot(subset3, 'Boxplot of Danceability for Final Third of Genres')"},"cell_type":"code","id":"934eefe5-5960-4033-9235-f6c4a5162ed0","execution_count":99,"outputs":[]},{"source":"### Recommendation","metadata":{},"cell_type":"markdown","id":"26f9207d-f084-4029-ab2d-f9052d493061"},{"source":"Boxplots are valuable for understanding data distribution patterns. By closely examining each sub-boxplot, we can identify genres that are unsuitable for further analysis and modeling based on their danceability distribution and even checking outliers.\nGenres with lowest danceability scores on average:\n- iranian\n- sleep\n- grindcore\n- opera\n\nHowever, it's also essential to consider our context, as we are curating a playlist for a company's dance party. Genres like \"children\" and \"kids\" are likely irrelevant for our specific goal. Even songs which are ambient, or belong to classical genre are not suitable for dancing.\n\nFollowing is the list of genres that are not being considered:","metadata":{},"cell_type":"markdown","id":"e067c798-345a-4b2a-a264-f49ba8e64983"},{"source":"### Dropping Irrelevant Genres","metadata":{},"cell_type":"markdown","id":"3204d1d7-712d-498f-9ef0-84d5892f42c5"},{"source":"genres_to_drop = ['children','study','sad','emo','kids','black-metal','opera','sleep','classical','ambient','death metal','grindcore','iranian','new-age','disney','idm','grunge']\n\n# Create a new DataFrame without the specified genres\nspotify =spotify[~spotify['track_genre'].isin(genres_to_drop)]","metadata":{"executionCancelledAt":null,"executionTime":45,"lastExecutedAt":1696001913536,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"genres_to_drop = ['children','study','sad','emo','kids','black-metal','opera','sleep','classical','ambient','death metal','grindcore','iranian','new-age','disney','idm','grunge']\n\n# Create a new DataFrame without the specified genres\nspotify =spotify[~spotify['track_genre'].isin(genres_to_drop)]"},"cell_type":"code","id":"9559e555-256f-41c4-9862-07d4e4fed009","execution_count":100,"outputs":[]},{"source":"genres2=spotify[\"track_genre\"].unique()\ngenres2","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1696001913585,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"genres2=spotify[\"track_genre\"].unique()\ngenres2"},"cell_type":"code","id":"afcc77dc-e473-4102-b9cc-9ee6c1c3662e","execution_count":101,"outputs":[]},{"source":"This further reduces the number of rows in our dataset to even more relevant data for our context.","metadata":{},"cell_type":"markdown","id":"e40cdb39-a48e-46f2-9ac1-4b723b58cb75"},{"source":"# Print the resulting DataFrame\nspotify","metadata":{"executionCancelledAt":null,"executionTime":145,"lastExecutedAt":1696001913730,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Print the resulting DataFrame\nspotify","outputsMetadata":{"0":{"height":331,"type":"dataFrame"}}},"cell_type":"code","id":"fd0022a7-154d-43c3-aaf3-c7140b7fbcb0","execution_count":102,"outputs":[]},{"source":"## üéº Audio Features\nLet's now explore the actual audio features and see where it takes us!","metadata":{},"cell_type":"markdown","id":"84c14ce8-116e-44c9-8041-dbd4300feb13"},{"source":"### Data pre-processing","metadata":{},"cell_type":"markdown","id":"58ce0faa-39a3-403d-9b7c-ac3e0e2e16ea"},{"source":"As mentioned earlier in the notebook, 25% of the values in instrumentalness column were 0. Let us deal with them. First we find the count of such values and then impute them with mean value of the column","metadata":{},"cell_type":"markdown","id":"4e75124d-4904-49b9-bd1f-e5fd16196e04"},{"source":"count = spotify[\"instrumentalness\"].value_counts()[0]\ncount","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1696001913781,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"count = spotify[\"instrumentalness\"].value_counts()[0]\ncount"},"cell_type":"code","id":"ac96c8e0-d0bf-48e4-9935-b0f6221815be","execution_count":103,"outputs":[]},{"source":"#Replacing '0' values with mean\nspotify['instrumentalness'] = spotify['instrumentalness'].replace(0, spotify['instrumentalness'].mean())\nprint(spotify['instrumentalness'])","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1696001913828,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Replacing '0' values with mean\nspotify['instrumentalness'] = spotify['instrumentalness'].replace(0, spotify['instrumentalness'].mean())\nprint(spotify['instrumentalness'])","outputsMetadata":{"0":{"height":251,"type":"stream"}}},"cell_type":"code","id":"06ae7cc0-43b6-4b7f-a40c-a3dca882c8ac","execution_count":104,"outputs":[]},{"source":"Let us now convert boolean values in explicit columns to 0 or 1. Where 0 indicates False value and 1 indicated True value.","metadata":{},"cell_type":"markdown","id":"307b9bef-7942-47c2-ac51-6803d3c13f92"},{"source":"spotify['explicit'] = spotify['explicit'].astype(int)\nspotify['explicit']","cell_type":"code","id":"60493996-ee30-4018-9ebb-622928aeb4d3","outputs":[],"metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1696001913877,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"spotify['explicit'] = spotify['explicit'].astype(int)\nspotify['explicit']"},"execution_count":105},{"source":"## üí° Correlation of features with danceability","metadata":{},"cell_type":"markdown","id":"cbb48455-e545-42b8-9519-29e4373c619c"},{"source":"### Heatmap","metadata":{},"cell_type":"markdown","id":"c8751d10-635d-40fb-8b6a-6f0c1e33e53a"},{"source":"This heatmap visualization, created using Seaborn, offers a vivid representation of how different attributes interact. Bright spots indicate strong positive correlations, while darker areas suggest weaker or negative associations. Analyzing these correlations is essential for understanding the interplay of musical features and can help us uncover fascinating insights into the world of music","metadata":{},"cell_type":"markdown","id":"5dcd817b-ab35-4e06-981e-6bda52241885"},{"source":"correlation = spotify.corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(correlation, annot=True)\nplt.xticks(rotation=45)\nplt.yticks(fontsize=10)\nplt.show()","metadata":{"executionCancelledAt":null,"executionTime":645,"lastExecutedAt":1696001914522,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"correlation = spotify.corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(correlation, annot=True)\nplt.xticks(rotation=45)\nplt.yticks(fontsize=10)\nplt.show()"},"cell_type":"code","id":"d3ef36c0-41de-4f97-ad6a-e67a9a2b621c","execution_count":106,"outputs":[]},{"source":"It is clear from the above heatmap that valence is highly correlated with danceability.It would be too early to disregard the rest as correlation is just one face of analysis.","metadata":{},"cell_type":"markdown","id":"05740086-1001-4256-a69c-2fde0242dc69"},{"source":"### Histograms","metadata":{},"cell_type":"markdown","id":"46c90555-bda1-4898-8be6-923f349dcd1c"},{"source":"Let us plot histograms to analyse each audio feature at once for a better understanding.","metadata":{},"cell_type":"markdown","id":"4ece024d-d081-4465-9a02-33be9cb6554e"},{"source":"spotify.hist(figsize=(15,15), color='purple')\nplt.tight_layout()\nplt.show()","metadata":{"executionCancelledAt":null,"executionTime":1883,"lastExecutedAt":1696001916405,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"spotify.hist(figsize=(15,15), color='purple')\nplt.tight_layout()\nplt.show()"},"cell_type":"code","id":"e0831ce3-adb1-493d-8a50-fe05a7356107","execution_count":107,"outputs":[]},{"source":"### Recommendation","metadata":{},"cell_type":"markdown","id":"2acc71ed-5db6-4be2-a27c-f1b196bce2c9"},{"source":"The histograms provide a visual representation of the distribution of each audio feature in the Spotify dataset. \n- The 'duration' distribution is also not uniform across the data and can be dropped.\n\n- The 'explicit' distribution is again discrete, and since most of the songs are non-explicit, we can drop this feature.\n\n- Most of the distributions are skewed and hence a suitable scaling technique is required for processing the dataset.","metadata":{},"cell_type":"markdown","id":"46578635-0091-41b4-b979-424466369a3e"},{"source":"Dropping the features that might not be necessary for further analysis:","metadata":{},"cell_type":"markdown","id":"94878133-b33a-4b81-be0d-68d270c45727"},{"source":"spotify=spotify.drop(['track_id','album_name','duration_ms',],axis=1)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1696001916456,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"spotify=spotify.drop(['track_id','album_name','duration_ms',],axis=1)"},"cell_type":"code","id":"807766cb-1173-40c8-b2f0-683e5acd7820","execution_count":108,"outputs":[]},{"source":"### Individual Correlation with Danceability\nIn this segment of our exploration, we turn to the Yellowbrick library to shed light on the relationships between various musical attributes and the 'danceability' of tracks in our Spotify dataset.\nBy examining how different features interact with the 'danceability' of music tracks, we gain a deeper understanding of which attributes have a significant impact and in what direction. This knowledge becomes invaluable for making informed decisions in our analysis and modeling processes, particularly when curating a playlist for a company's dance party.","metadata":{},"cell_type":"markdown","id":"4111b762-95d9-4c73-94c5-8417db145923"},{"source":"import numpy as np\nfrom sklearn import datasets\nfrom yellowbrick.target.feature_correlation import feature_correlation\n\nX, y = spotify.drop(['track_name','danceability','track_genre','artists'], axis=1), spotify['danceability']\nfeature_names = X.columns.tolist()\nfeatures = np.array(feature_names)\nvisualizer = feature_correlation(X, y, labels=features)\nplt.tight_layout()","metadata":{"executionCancelledAt":null,"executionTime":449,"lastExecutedAt":1696001916906,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nfrom sklearn import datasets\nfrom yellowbrick.target.feature_correlation import feature_correlation\n\nX, y = spotify.drop(['track_name','danceability','track_genre','artists'], axis=1), spotify['danceability']\nfeature_names = X.columns.tolist()\nfeatures = np.array(feature_names)\nvisualizer = feature_correlation(X, y, labels=features)\nplt.tight_layout()"},"cell_type":"code","id":"940eec64-0b9e-4dd3-8697-71dea18b3c17","execution_count":109,"outputs":[]},{"source":"This diverging plot gives us a better picture of the type of correlation of features with the target feature i.e Danceability","metadata":{},"cell_type":"markdown","id":"1289addc-4558-48ef-b46c-e40e133e9dd3"},{"source":"### Scatter Plots\nEach plot explores the correlation between danceability and specific audio features of music tracks. The code below employs Linear Regression to analyze the relationships between danceability and audio features such as Valence, Speechiness, Acousticness, Liveness, Energy, and Instrumentalness.","metadata":{},"cell_type":"markdown","id":"2211b881-ab40-49cb-8021-d28507efe277"},{"source":"import matplotlib.ticker as ticker\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef plot_feature(ax, feature_name, X, y, x_label):\n    regr = LinearRegression()\n    regr.fit(X, y)\n\n    ax.scatter(X, y, alpha=0.5, label=f'{feature_name} vs. Danceability')\n    ax.plot(X, regr.predict(X), color=\"red\", linewidth=3)\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(\"Danceability\")\n    ax.set_title(\"Correlation\")\n\n# Create a single figure for all the subplots\nfig, axes = plt.subplots(3, 3, figsize=(20, 10))\nfig.subplots_adjust(wspace=0.3, hspace=0.5)\n\n# List of features and their corresponding column names\nfeatures = [\"Valence\", \"Speechiness\", \"Acousticness\", \"Liveness\", \"Energy\", \"Instrumentalness\", \"Loudness\", \"Tempo\",\"Popularity\"]\ncolumns = [\"valence\", \"speechiness\", \"acousticness\", \"liveness\", \"energy\", \"instrumentalness\", \"loudness\", \"tempo\",\"popularity\"]\n\nfor i, feature_name in enumerate(features):\n    row, col = divmod(i, 3)\n    plot_feature(\n        axes[row, col],\n        feature_name,\n        spotify[[columns[i]]].values,\n        spotify[\"danceability\"].values,\n        feature_name\n    )\nplt.show()\n","metadata":{"executionCancelledAt":null,"executionTime":2038,"lastExecutedAt":1696001918944,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import matplotlib.ticker as ticker\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef plot_feature(ax, feature_name, X, y, x_label):\n    regr = LinearRegression()\n    regr.fit(X, y)\n\n    ax.scatter(X, y, alpha=0.5, label=f'{feature_name} vs. Danceability')\n    ax.plot(X, regr.predict(X), color=\"red\", linewidth=3)\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(\"Danceability\")\n    ax.set_title(\"Correlation\")\n\n# Create a single figure for all the subplots\nfig, axes = plt.subplots(3, 3, figsize=(20, 10))\nfig.subplots_adjust(wspace=0.3, hspace=0.5)\n\n# List of features and their corresponding column names\nfeatures = [\"Valence\", \"Speechiness\", \"Acousticness\", \"Liveness\", \"Energy\", \"Instrumentalness\", \"Loudness\", \"Tempo\",\"Popularity\"]\ncolumns = [\"valence\", \"speechiness\", \"acousticness\", \"liveness\", \"energy\", \"instrumentalness\", \"loudness\", \"tempo\",\"popularity\"]\n\nfor i, feature_name in enumerate(features):\n    row, col = divmod(i, 3)\n    plot_feature(\n        axes[row, col],\n        feature_name,\n        spotify[[columns[i]]].values,\n        spotify[\"danceability\"].values,\n        feature_name\n    )\nplt.show()\n"},"cell_type":"code","id":"09a24925-441c-4aa8-8fa5-799ddcfaacc0","execution_count":110,"outputs":[]},{"source":"### Recommendation","metadata":{},"cell_type":"markdown","id":"a6744696-9582-4b46-86e4-f3573f1df086"},{"source":"The scatter plots above are a better explanation of the histograms we saw earlier.\n- Valence, energy and loudness have the most prominent positive linear relationship with danceability.\n- Acousticness, liveness, intrumentalness and tempo have negative relationship with danceability.\n- Popularity and key are int type so they can be analysed in a different manner.","metadata":{},"cell_type":"markdown","id":"b03d9c8b-6011-4f80-bffd-ff67c95f797b"},{"source":"It is very apparent that valence is the strongest indicator of a song's danceability. However, the same cannot be said for speechiness due to a large concentration of outliers in the extreme ends of the graph even though there is a positive correlation.\nEnergy and loudness can also be considered as  decent positive indicators of a song's danceability","metadata":{},"cell_type":"markdown","id":"8d1032c2-d266-474c-89ac-edd8cae2134c"},{"source":"## üõ† Processing Data","metadata":{},"cell_type":"markdown","id":"594dc0b6-a1f4-4fad-872f-6be8a2a56422"},{"source":"As we observed from the plotted histograms above, most of the distribution of features is skewed such as that of energy, intrumentalness, acousticness,liveness and speechiness. It is important that we preprocess our data carefully.\n\nRobust Scaling is a suitable choice for preprocessing music-related data, especially when dealing with potentially skewed distributions and outliers. It helps ensure that the scaled data maintains its integrity, making it more suitable for various machine learning and data analysis tasks.","metadata":{},"cell_type":"markdown","id":"9c7669cb-d5f0-4237-a1f2-8676ec3b351c"},{"source":"from sklearn.preprocessing import RobustScaler\n# Select the columns to be scaled (exclude 'track_genre')\nnumeric_columns = ['popularity', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'explicit', 'mode']\n\n# Create a RobustScaler instance\nscaler = RobustScaler()\n\n# Apply Robust scaling to the selected columns\nspotify[numeric_columns] = scaler.fit_transform(spotify[numeric_columns])","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1696001918996,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.preprocessing import RobustScaler\n# Select the columns to be scaled (exclude 'track_genre')\nnumeric_columns = ['popularity', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'explicit', 'mode']\n\n# Create a RobustScaler instance\nscaler = RobustScaler()\n\n# Apply Robust scaling to the selected columns\nspotify[numeric_columns] = scaler.fit_transform(spotify[numeric_columns])"},"cell_type":"code","id":"9d6a62c5-1e15-4049-87c2-35cbf40c8527","execution_count":111,"outputs":[]},{"source":"spotify","metadata":{"executionCancelledAt":null,"executionTime":174,"lastExecutedAt":1696001919171,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"spotify","outputsMetadata":{"0":{"height":331,"type":"dataFrame"}}},"cell_type":"code","id":"f4c53461-0df6-47ac-b458-a4d52174935c","execution_count":112,"outputs":[]},{"source":"Our features are now scaled according to the requirement.","metadata":{},"cell_type":"markdown","id":"0d7925b5-a4a7-405d-9dc2-922b492faf6d"},{"source":"## Clustering for Genre\nSince there are too many genres, encoding them individually would increase the dimensionality of the dataset. Hence another way of including the genres for our task is to create meaningful clusters of genres. This can be done by creating clusters of genres not only based on daceability but also on valence which is highly correlated with danceability.\n\nValence reflects the emotional mood of a song, while danceability measures its rhythmic and tempo characteristics. Clustering based on these features makes genres more interpretable, relevant to how listeners perceive music, and useful for recommendations and creative exploration","metadata":{},"cell_type":"markdown","id":"04151276-925c-459b-a5be-a2ccf85a641a"},{"source":"### Calculating Genre Statistics","metadata":{},"cell_type":"markdown","id":"302c67a3-c74a-4b85-ba4c-0e86838cf0b7"},{"source":"Our first task is to calculate the mean danceability and valence score for each genre. This step condenses the numerous tracks within a genre into a single attribute representing its average danceability. ","metadata":{},"cell_type":"markdown","id":"70f8c2cd-2e80-4464-af5d-c96cbb56994c"},{"source":"# Calculate the mean danceability and mean valence for each genre\ngenre_stats = spotify.groupby('track_genre').agg({'danceability': 'mean', 'valence': 'mean'}).reset_index()","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1696001919220,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Calculate the mean danceability and mean valence for each genre\ngenre_stats = spotify.groupby('track_genre').agg({'danceability': 'mean', 'valence': 'mean'}).reset_index()"},"cell_type":"code","id":"d4973faa-9808-45d1-ada2-7d084c482c25","execution_count":113,"outputs":[]},{"source":"### üïµÔ∏è‚Äç‚ôÄÔ∏è Finding the Optimal Number of Clusters","metadata":{},"cell_type":"markdown","id":"d85f8c1a-3657-4466-b976-afbcdfab240b"},{"source":"\nNow, let's use clustering to group genres based on their danceability scores. We can employ the \"Elbow Method\" to help us decide. This technique involves running the clustering algorithm for different values of K and plotting a graph of the distortion (sum of squared distances from each point to its assigned center) against K.","metadata":{},"cell_type":"markdown","id":"56ccf1c2-108c-4736-ad43-0e76a95a64a3"},{"source":"from sklearn.cluster import KMeans\nfrom scipy.spatial.distance import cdist\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nrange_n_clusters = [3, 4, 5, 6, 7]\ndistortions = []\n\nfor num_clusters in range_n_clusters:\n    # initialise kmeans\n    kmeans = KMeans(n_clusters=num_clusters)\n    kmeans.fit(genre_stats[['danceability', 'valence']])\n    cluster_labels = kmeans.labels_\n    \n    # calculate distortion\n    distortions.append(sum(np.min(cdist(genre_stats[['danceability', 'valence']], kmeans.cluster_centers_, 'euclidean'), axis=1)) / genre_stats.shape[0])\n\nplt.plot(range_n_clusters, distortions, 'bx-')\nplt.xlabel('Values of K') \nplt.ylabel('Distortion') \nplt.title('Elbow Method For Optimal k')\nplt.show()","metadata":{"executionCancelledAt":null,"executionTime":233,"lastExecutedAt":1696001919453,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.cluster import KMeans\nfrom scipy.spatial.distance import cdist\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nrange_n_clusters = [3, 4, 5, 6, 7]\ndistortions = []\n\nfor num_clusters in range_n_clusters:\n    # initialise kmeans\n    kmeans = KMeans(n_clusters=num_clusters)\n    kmeans.fit(genre_stats[['danceability', 'valence']])\n    cluster_labels = kmeans.labels_\n    \n    # calculate distortion\n    distortions.append(sum(np.min(cdist(genre_stats[['danceability', 'valence']], kmeans.cluster_centers_, 'euclidean'), axis=1)) / genre_stats.shape[0])\n\nplt.plot(range_n_clusters, distortions, 'bx-')\nplt.xlabel('Values of K') \nplt.ylabel('Distortion') \nplt.title('Elbow Method For Optimal k')\nplt.show()"},"cell_type":"code","id":"f1b1e57d-4634-480b-bc00-47498af2cf75","execution_count":114,"outputs":[]},{"source":"In the resulting graph, you'll notice the first distinctive \"elbow point,\" where the distortion starts to decrease at a slower rate. This point suggests the optimal number of clusters which is k=4. In our case, it helps us determine how many distinct clusters of music genres exist based on their danceability scores.","metadata":{},"cell_type":"markdown","id":"95267689-06c0-4121-9804-5b73839c25bf"},{"source":"# Number of clusters (you can adjust this based on your preference)\nnum_clusters = 4\n\n# Perform K-Means clustering based on mean danceability and mean valence\nkmeans = KMeans(n_clusters=num_clusters, random_state=10)\ngenre_stats['cluster'] = kmeans.fit_predict(genre_stats[['danceability', 'valence']])\ncustom_cluster_labels = list(range(num_clusters))\n\n# Plot the clusters\nplt.scatter(genre_stats['danceability'], genre_stats['valence'], c=genre_stats['cluster'], cmap='rainbow')\nplt.xlabel('Mean Danceability')\nplt.ylabel('Mean Valence')\nplt.title('Clusters of Music Genres Based on Mean Danceability and Mean Valence')\nplt.show()\n\n# Display the cluster assignments\nprint(genre_stats[['track_genre', 'danceability', 'valence', 'cluster']])","metadata":{"executionCancelledAt":null,"executionTime":206,"lastExecutedAt":1696001919660,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Number of clusters (you can adjust this based on your preference)\nnum_clusters = 4\n\n# Perform K-Means clustering based on mean danceability and mean valence\nkmeans = KMeans(n_clusters=num_clusters, random_state=10)\ngenre_stats['cluster'] = kmeans.fit_predict(genre_stats[['danceability', 'valence']])\ncustom_cluster_labels = list(range(num_clusters))\n\n# Plot the clusters\nplt.scatter(genre_stats['danceability'], genre_stats['valence'], c=genre_stats['cluster'], cmap='rainbow')\nplt.xlabel('Mean Danceability')\nplt.ylabel('Mean Valence')\nplt.title('Clusters of Music Genres Based on Mean Danceability and Mean Valence')\nplt.show()\n\n# Display the cluster assignments\nprint(genre_stats[['track_genre', 'danceability', 'valence', 'cluster']])","outputsMetadata":{"1":{"height":290,"type":"stream"}}},"cell_type":"code","id":"99a673cd-791c-47bc-8003-8497461d1897","execution_count":115,"outputs":[]},{"source":"Since we have have our genre clusters now, we no longer need the original track genre information so we can use a mapping operation to replace the original 'track_genre' values in the Spotify dataset with corresponding cluster labels.","metadata":{},"cell_type":"markdown","id":"81d9905f-f1be-47d5-b5b0-3a9897eadaa6"},{"source":"genre_to_cluster = dict(zip(genre_stats['track_genre'], genre_stats['cluster']))\n# Use the mapping to replace track_genre in the original Spotify dataset\nspotify['track_genre'] = spotify['track_genre'].map(genre_to_cluster)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1696001919708,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"genre_to_cluster = dict(zip(genre_stats['track_genre'], genre_stats['cluster']))\n# Use the mapping to replace track_genre in the original Spotify dataset\nspotify['track_genre'] = spotify['track_genre'].map(genre_to_cluster)"},"cell_type":"code","id":"674360a8-a910-49af-8730-7e472bb2d4c7","execution_count":116,"outputs":[]},{"source":"spotify","metadata":{"executionCancelledAt":null,"executionTime":170,"lastExecutedAt":1696001919878,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"spotify","outputsMetadata":{"0":{"height":331,"type":"dataFrame"}}},"cell_type":"code","id":"7911aca7-54fa-43fb-99fc-38c02bd18d71","execution_count":117,"outputs":[]},{"source":"We have our clusters but that is not the end of our problem here. Now the track genre column is out of scale as compared to other features. So we can use One-hot encoding to transform our clusters to make them interpretable to the model.","metadata":{},"cell_type":"markdown","id":"6f4cb20d-6df9-4433-81fd-4f319a2466a0"},{"source":"#One-hot encoding\nspotify = pd.get_dummies(spotify, columns=['track_genre'], prefix='genre')","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1696001919928,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#One-hot encoding\nspotify = pd.get_dummies(spotify, columns=['track_genre'], prefix='genre')"},"cell_type":"code","id":"cae37443-53f9-4ff5-b969-cba68607a4b9","execution_count":118,"outputs":[]},{"source":"spotify","metadata":{"executionCancelledAt":null,"executionTime":161,"lastExecutedAt":1696001920089,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"spotify","outputsMetadata":{"0":{"height":331,"type":"dataFrame"}}},"cell_type":"code","id":"0c850bb6-3994-44a3-8a5a-9d3e0ba3abf2","execution_count":119,"outputs":[]},{"source":"The dataset seems good to go now.","metadata":{},"cell_type":"markdown","id":"b870d3e6-269a-4cea-b46c-c8919b74f81d"},{"source":"## ü§ñ ML Modeling\nNow that we have the complete picture of our data, it is time to call our DJ and get the party started. Our DJ here is none other than our Machine Learning model that would predict the Top 50 danceable songs for us.","metadata":{},"cell_type":"markdown","id":"ee0f975d-5806-4fce-ae64-2a7de2465474"},{"source":"### Feature Selection","metadata":{},"cell_type":"markdown","id":"45f35e19-5f97-402f-b784-e910bb2fb877"},{"source":"In the data preparation process for machine learning modeling, relevant features have been thoughtfully selected to predict track 'danceability'. Instrumentalness,explicit,speechiness have not been considered in the process due to having little or no effect in determining danceability of a song. The categorical features such as track name and track id have also been omitted for smooth training, leaving our dataset ready for machine learning algorithms to unveil the factors that truly determine a song's dance-worthiness.","metadata":{},"cell_type":"markdown","id":"eb1e156d-684f-4e90-80d2-4a847844847a"},{"source":"# Select relevant features and the target variable\nfeatures =[\"popularity\",\"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\"acousticness\",\"liveness\",\n         \"valence\",\"tempo\",\"time_signature\",\"genre_0\",\"genre_1\",\"genre_2\",\"genre_3\"]\n#categorical_feature = ['track_genre']  # Add 'track_genre' as a categorical feature\ntarget = ['danceability']","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1696001920136,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Select relevant features and the target variable\nfeatures =[\"popularity\",\"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\"acousticness\",\"liveness\",\n         \"valence\",\"tempo\",\"time_signature\",\"genre_0\",\"genre_1\",\"genre_2\",\"genre_3\"]\n#categorical_feature = ['track_genre']  # Add 'track_genre' as a categorical feature\ntarget = ['danceability']","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"cell_type":"code","id":"55cd1260-28a9-4f1e-96ee-a4588ea6eab1","execution_count":120,"outputs":[]},{"source":"### Traint-Test Split\nNow, it's time to split our dataset into two parts: training and testing. Allocating 80% of the data for training machine learning models and reserving 20% for performance testing is essential for model generalization. A fixed random seed (random_state=42) guarantees consistent and comparable results across runs.","metadata":{},"cell_type":"markdown","id":"9a8799a0-271c-4be4-88d1-a56d0567bffa"},{"source":"from sklearn.model_selection import train_test_split\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(spotify[features], spotify[target], test_size=0.2, random_state=10)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1696001920184,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.model_selection import train_test_split\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(spotify[features], spotify[target], test_size=0.2, random_state=10)"},"cell_type":"code","id":"28f8887d-a76d-4bf1-bdad-11d45a2263ce","execution_count":121,"outputs":[]},{"source":"from sklearn.metrics import mean_squared_error, make_scorer, r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score\nimport xgboost as xgb\nmodels = [\n    RandomForestRegressor(n_estimators=50,max_depth=5,min_samples_split=5,random_state=10), \n    xgb.XGBRegressor(n_estimators=50, random_state=42,alpha=1.0),\n    SVR(),\n    KNeighborsRegressor()\n]\nmodel_names = ['Random Forest', 'XGBoost','SVM', 'KNN']\nmse_scores = []\nr2_scores = []\nfor model in models:\n    mse_scores.append(-cross_val_score(model, X_train, y_train, cv=5,\n                                       scoring='neg_mean_squared_error').mean())\n    r2_scores.append(cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean())\nresults = pd.DataFrame({'Model': model_names, 'MSE': mse_scores, 'R-squared': r2_scores})\nprint(results)","metadata":{"executionCancelledAt":null,"executionTime":94215,"lastExecutedAt":1696002014400,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.metrics import mean_squared_error, make_scorer, r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score\nimport xgboost as xgb\nmodels = [\n    RandomForestRegressor(n_estimators=50,max_depth=5,min_samples_split=5,random_state=10), \n    xgb.XGBRegressor(n_estimators=50, random_state=42,alpha=1.0),\n    SVR(),\n    KNeighborsRegressor()\n]\nmodel_names = ['Random Forest', 'XGBoost','SVM', 'KNN']\nmse_scores = []\nr2_scores = []\nfor model in models:\n    mse_scores.append(-cross_val_score(model, X_train, y_train, cv=5,\n                                       scoring='neg_mean_squared_error').mean())\n    r2_scores.append(cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean())\nresults = pd.DataFrame({'Model': model_names, 'MSE': mse_scores, 'R-squared': r2_scores})\nprint(results)","outputsMetadata":{"0":{"height":114,"type":"stream"}}},"cell_type":"code","id":"d6805d44-df10-4aa7-a64a-f1471a2f0c73","execution_count":122,"outputs":[]},{"source":"Although, RandomForest and XGBoost clearly seem to outperform other algorithms, their R2 score might indicate a tendecy to overfit. This could be due to many reasons, but for the sake of simplicity we can safely decide to go ahead with KNN Regressor due to it's fair R2 score and acceptable MSE. Also KNN is non-parametric, which means it can capture complex relationships in the data without assuming a specific functional form.","metadata":{},"cell_type":"markdown","id":"ab622352-f19f-4cf7-9fa1-cea96c97b4ee"},{"source":"from sklearn.neighbors import KNeighborsRegressor\n\n# Create a KNN regression model\nknn_model = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors (n_neighbors) as needed\n\n# Fit the KNN model to the training data\nknn_model.fit(X_train, y_train.values.ravel())\n\n# Predict danceability scores for all songs in the dataset using features prepared above\nspotify['predicted_danceability'] = knn_model.predict(spotify[features])\n\n# Sort the data by predicted danceability score in descending order\nspotify.sort_values(by='predicted_danceability', ascending=False, inplace=True)","metadata":{"executionCancelledAt":null,"executionTime":12627,"lastExecutedAt":1696002027028,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.neighbors import KNeighborsRegressor\n\n# Create a KNN regression model\nknn_model = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors (n_neighbors) as needed\n\n# Fit the KNN model to the training data\nknn_model.fit(X_train, y_train.values.ravel())\n\n# Predict danceability scores for all songs in the dataset using features prepared above\nspotify['predicted_danceability'] = knn_model.predict(spotify[features])\n\n# Sort the data by predicted danceability score in descending order\nspotify.sort_values(by='predicted_danceability', ascending=False, inplace=True)"},"cell_type":"code","id":"01c1da63-5e19-4d15-8d2f-dcdc6cf89718","execution_count":123,"outputs":[]},{"source":"## üìà Performace Evaluation\nMAE, MSE and R2 score collectively provide insights into how well the RandomForestRegressor model is performing in predicting danceability scores. A lower MAE and MSE, along with a higher R-squared, indicate better model performance. It's essential to evaluate these metrics to ensure that the model meets the desired level of accuracy and can effectively predict danceability in your dataset.","metadata":{},"cell_type":"markdown","id":"4f704797-acc1-4972-9cab-87b1a2e389fd"},{"source":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n# Calculate predictions on the test set\ny_pred = knn_model.predict(X_test)\n\n# Calculate evaluation metrics\nmae= mean_absolute_error(y_test, y_pred)\nmse= mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Absolute Error (MAE): {mae:.6f}\")\nprint(f\"Mean Squared Error (MSE): {mse:.8f}\")\nprint(f\"R-squared (R^2): {r2:.4f}\")","metadata":{"executionCancelledAt":null,"executionTime":2605,"lastExecutedAt":1696002029634,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n# Calculate predictions on the test set\ny_pred = knn_model.predict(X_test)\n\n# Calculate evaluation metrics\nmae= mean_absolute_error(y_test, y_pred)\nmse= mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Absolute Error (MAE): {mae:.6f}\")\nprint(f\"Mean Squared Error (MSE): {mse:.8f}\")\nprint(f\"R-squared (R^2): {r2:.4f}\")","outputsMetadata":{"0":{"height":75,"type":"stream"}}},"cell_type":"code","id":"3afc94a9-ba6a-4685-8e15-e042d07a4b7f","execution_count":124,"outputs":[]},{"source":"- The MAE measures the average absolute difference between the actual and predicted values. In this case, a MAE of 0.08 indicates that, on average, the model's predictions have an absolute difference of 0.139 from the actual values.\n- A lower MAE is generally better, so a MAE of 0.139 suggests that the model's predictions are relatively close to the actual values.\n- The MSE is similar to MAE but squares the differences before averaging them. A lower MSE indicates a better fit of the model to the data.\n- With an MSE of 0.03, the model's predictions have, on average, a squared difference of 0.03 from the actual values.\n- An R^2 value of 0.935 indicates that approximately 94% of the variability in the target variable can be explained by the model's independent variables.","metadata":{},"cell_type":"markdown","id":"c95e627a-126f-4267-a54e-b219053b2cb8"},{"source":"### Regression Plot\nThis scatter plot provides a clear comparison between the predicted (in blue) and actual (in red) danceability scores for a collection of songs. Each point on the plot represents a song, and their positions relative to the diagonal line (where actual equals predicted) reveal how closely the predictions align with reality. This visual assessment helps us gauge the accuracy of our predictive model, with points clustering around the diagonal line indicating more accurate predictions.","metadata":{},"cell_type":"markdown","id":"090e8d74-c284-41c7-a014-c7157a13f3ca"},{"source":"danceability = spotify['danceability']\npredicted_danceability = spotify['predicted_danceability']\n\n# Create a scatter plot for actual danceability (in blue)\nplt.figure(figsize=(10, 6))\nplt.scatter(danceability, predicted_danceability, alpha=0.05, label='Predicted', color='blue',s=20)\n\n# Create a scatter plot for predicted danceability (in red)\nplt.scatter(danceability, danceability, alpha=0.05, label='Actual', color='red',s=10)\n\nplt.title('Scatter Plot: Actual vs. Predicted Danceability')\nplt.xlabel('Actual Danceability')\nplt.ylabel('Predicted Danceability')\nplt.grid(True)\n\n# Add a legend to distinguish between actual and predicted\nplt.legend(loc='best')\nplt.show()","metadata":{"executionCancelledAt":null,"executionTime":893,"lastExecutedAt":1696002030527,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"danceability = spotify['danceability']\npredicted_danceability = spotify['predicted_danceability']\n\n# Create a scatter plot for actual danceability (in blue)\nplt.figure(figsize=(10, 6))\nplt.scatter(danceability, predicted_danceability, alpha=0.05, label='Predicted', color='blue',s=20)\n\n# Create a scatter plot for predicted danceability (in red)\nplt.scatter(danceability, danceability, alpha=0.05, label='Actual', color='red',s=10)\n\nplt.title('Scatter Plot: Actual vs. Predicted Danceability')\nplt.xlabel('Actual Danceability')\nplt.ylabel('Predicted Danceability')\nplt.grid(True)\n\n# Add a legend to distinguish between actual and predicted\nplt.legend(loc='best')\nplt.show()"},"cell_type":"code","id":"fec11130-c0d7-4f73-8c10-1aff2ac9665f","execution_count":125,"outputs":[]},{"source":"### üé∂ The Playlist","metadata":{},"cell_type":"markdown","id":"f061cfa6-bc09-4eac-b8de-7c941e37cc93"},{"source":"# Extract the top 50 songs\ntop_50_danceable_songs= spotify.head(50)\n\n# Display the top 50 danceable songs\ntop_50_danceable_songs[['track_name', 'artists', 'predicted_danceability']]","metadata":{"executionCancelledAt":null,"executionTime":62,"lastExecutedAt":1696002030589,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Extract the top 50 songs\ntop_50_danceable_songs= spotify.head(50)\n\n# Display the top 50 danceable songs\ntop_50_danceable_songs[['track_name', 'artists', 'predicted_danceability']]","outputsMetadata":{"0":{"height":313,"type":"dataFrame"}}},"cell_type":"code","id":"2b156f39-de83-407f-8dd8-7f01fa3f119b","execution_count":126,"outputs":[]},{"source":"Voila! We have our top 50 dance songs for the ultimate summer party, but our work here is not done yet, to add a little spice to this playlist, let us develop an algorithm that orders these 50 songs like how a DJ would. Typically in a party setting, DJs start with a selection of songs that have a moderate tempo and gradually increase the energy level as the party progresses. They may begin with some well-known and easy-to-dance-to tracks and then transition to more energetic beats.","metadata":{},"cell_type":"markdown","id":"33451e73-8570-4d43-ab61-28d59bac49cd"},{"source":"from sklearn.preprocessing import MinMaxScaler\n\n# Define the weights for each feature based on importance\nweights = {\n    'valence': 0.25,   # Adjust the weight for valence based on importance\n    'popularity': 0.35,  # Adjust the weight for popularity based on importance\n    'energy': 0.25,     # Adjust the weight for energy based on importance\n    'tempo': 0.15      # Adjust the weight for tempo based on importance\n}\n\n# Create a Min-Max scaler\nscaler = MinMaxScaler()\n\n# Normalize the feature columns except 'track_name' and 'artists'\nnormalized_features = top_50_danceable_songs[['valence', 'popularity', 'energy', 'tempo']].copy()\nnormalized_features = scaler.fit_transform(normalized_features)\ntop_50_danceable_songs[['valence', 'popularity', 'energy', 'tempo']] = normalized_features\n\n# Calculate a weighted score for each song using the defined weights\ntop_50_danceable_songs['weighted_score'] = (\n    top_50_danceable_songs['valence'] * weights['valence'] +\n    top_50_danceable_songs['popularity'] * weights['popularity'] +\n    top_50_danceable_songs['energy'] * weights['energy'] +\n    top_50_danceable_songs['tempo'] * weights['tempo']\n)\n\n# Filter songs with moderate to high tempo\nmoderate_to_high_tempo_songs = top_50_danceable_songs[top_50_danceable_songs['tempo'] >= 0.5]\n\n# Calculate how many additional songs are needed to reach a total of 50\nadditional_songs_needed = 50 - len(moderate_to_high_tempo_songs)\n\n# If additional songs are needed, select them from lower tempo range\nif additional_songs_needed > 0:\n    low_tempo_songs = top_50_danceable_songs[top_50_danceable_songs['tempo'] < 0.5]\n    # Sort the low tempo songs by weighted score in descending order and select the top ones\n    additional_songs = low_tempo_songs.sort_values(by='weighted_score', ascending=False).head(additional_songs_needed)\n    # Concatenate the additional songs with the moderate to high tempo songs\n    final_song_list = pd.concat([moderate_to_high_tempo_songs, additional_songs])\nelse:\n    # If no additional songs are needed, use only the moderate to high tempo songs\n    final_song_list = moderate_to_high_tempo_songs\n\n# Sort the final list of songs by weighted score in descending order\nplaylist = final_song_list.sort_values(by='weighted_score', ascending=False)\nplaylist = playlist[playlist['artists'] != playlist['artists'].shift()]\n\n\n# Display the final list of songs\nprint(playlist[['track_name', 'artists', 'weighted_score']])\n","metadata":{"executionCancelledAt":null,"executionTime":28,"lastExecutedAt":1696002077322,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.preprocessing import MinMaxScaler\n\n# Define the weights for each feature based on importance\nweights = {\n    'valence': 0.25,   # Adjust the weight for valence based on importance\n    'popularity': 0.35,  # Adjust the weight for popularity based on importance\n    'energy': 0.25,     # Adjust the weight for energy based on importance\n    'tempo': 0.15      # Adjust the weight for tempo based on importance\n}\n\n# Create a Min-Max scaler\nscaler = MinMaxScaler()\n\n# Normalize the feature columns except 'track_name' and 'artists'\nnormalized_features = top_50_danceable_songs[['valence', 'popularity', 'energy', 'tempo']].copy()\nnormalized_features = scaler.fit_transform(normalized_features)\ntop_50_danceable_songs[['valence', 'popularity', 'energy', 'tempo']] = normalized_features\n\n# Calculate a weighted score for each song using the defined weights\ntop_50_danceable_songs['weighted_score'] = (\n    top_50_danceable_songs['valence'] * weights['valence'] +\n    top_50_danceable_songs['popularity'] * weights['popularity'] +\n    top_50_danceable_songs['energy'] * weights['energy'] +\n    top_50_danceable_songs['tempo'] * weights['tempo']\n)\n\n# Filter songs with moderate to high tempo\nmoderate_to_high_tempo_songs = top_50_danceable_songs[top_50_danceable_songs['tempo'] >= 0.5]\n\n# Calculate how many additional songs are needed to reach a total of 50\nadditional_songs_needed = 50 - len(moderate_to_high_tempo_songs)\n\n# If additional songs are needed, select them from lower tempo range\nif additional_songs_needed > 0:\n    low_tempo_songs = top_50_danceable_songs[top_50_danceable_songs['tempo'] < 0.5]\n    # Sort the low tempo songs by weighted score in descending order and select the top ones\n    additional_songs = low_tempo_songs.sort_values(by='weighted_score', ascending=False).head(additional_songs_needed)\n    # Concatenate the additional songs with the moderate to high tempo songs\n    final_song_list = pd.concat([moderate_to_high_tempo_songs, additional_songs])\nelse:\n    # If no additional songs are needed, use only the moderate to high tempo songs\n    final_song_list = moderate_to_high_tempo_songs\n\n# Sort the final list of songs by weighted score in descending order\nplaylist = final_song_list.sort_values(by='weighted_score', ascending=False)\nplaylist = playlist[playlist['artists'] != playlist['artists'].shift()]\n\n\n# Display the final list of songs\nprint(playlist[['track_name', 'artists', 'weighted_score']])\n","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"cell_type":"code","id":"4ad11526-c633-42d6-8e4f-b074c6ab5c8e","execution_count":128,"outputs":[]},{"source":"playlist[['track_name', 'artists', 'weighted_score']]","metadata":{"executionCancelledAt":null,"executionTime":61,"lastExecutedAt":1696002086017,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"playlist[['track_name', 'artists', 'weighted_score']]","outputsMetadata":{"0":{"height":313,"type":"dataFrame"}}},"cell_type":"code","id":"c622265d-f38c-4192-8fa8-c8cce88e209d","execution_count":129,"outputs":[]},{"source":"### The End","metadata":{},"cell_type":"markdown","id":"04bcc758-92ab-428d-aefe-8dfa1bf533fb"},{"source":"Our final playlist is ready to be played! I hope you enjoyed this groovy journey as much as I did. Any feedback is welcome! Let the dancing begin!","metadata":{},"cell_type":"markdown","id":"b8ec4f7b-3425-46c6-8174-bb8d7ba6f9f5"}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}